"""
Stock Crawler CLI - ë‹¨ì¼ ì§„ì…ì 
"""
import typer
from datetime import date, datetime
from typing import Optional
import pandas as pd
import os
from pathlib import Path
from config import config

app = typer.Typer(help="IPO ë°ì´í„° í¬ë¡¤ëŸ¬ CLI")


def _build_dependencies(headless: bool = config.HEADLESS):
    """
    ì˜ì¡´ì„± ì¡°ë¦½ (DI Container ì—­í• )
    
    Args:
        headless: Playwright í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ
        
    Returns:
        dict: ì¡°ë¦½ëœ ì˜ì¡´ì„± ê°ì²´ë“¤
    """
    from infra.adapters.utils.console_logger import ConsoleLogger
    from infra.adapters.utils.date_calculator import DateCalculator
    from infra.adapters.web.playwright_page_provider import PlaywrightPageProvider
    from infra.adapters.web.calendar_scraper_adapter import CalendarScraperAdapter
    from infra.adapters.web.detail_scraper_adapter import DetailScraperAdapter
    from infra.adapters.data.dataframe_mapper import DataFrameMapper
    from infra.adapters.data.excel_exporter import ExcelExporter
    from infra.adapters.data.fdr_adapter import FDRAdapter
    from core.services.crawler_service import CrawlerService
    from core.services.stock_price_enricher import StockPriceEnricher
    
    # 1. ìœ í‹¸ë¦¬í‹°
    logger = ConsoleLogger()
    date_calculator = DateCalculator()
    
    # 2. Data
    fdr_adapter = FDRAdapter()
    data_mapper = DataFrameMapper()
    data_exporter = ExcelExporter()  # config ì‚¬ìš©
    
    # 3. Storage
    from infra.adapters.storage.google_drive_adapter import GoogleDriveAdapter
    storage_adapter = GoogleDriveAdapter()

    # 3.5 Enrichment
    stock_enricher = StockPriceEnricher(
        ticker_mapper=fdr_adapter,
        market_data_provider=fdr_adapter,
        logger=logger
    )
    
    # 4. Web Scraping
    page_provider = PlaywrightPageProvider(headless=headless)
    calendar_scraper = CalendarScraperAdapter()
    detail_scraper = DetailScraperAdapter(
        logger=logger
    )
    
    # 5. Service
    crawler_service = CrawlerService(
        page_provider=page_provider,
        calendar_scraper=calendar_scraper,
        detail_scraper=detail_scraper,
        data_mapper=data_mapper,
        data_exporter=data_exporter,
        date_calculator=date_calculator,
        stock_enricher=stock_enricher,
        logger=logger
    )
    
    return {
        'crawler': crawler_service,
        'page_provider': page_provider,
        'logger': logger,
        'fdr': fdr_adapter,
        'exporter': data_exporter,
        'storage': storage_adapter,
    }


@app.command("full")
def full_crawl(
    start_year: int = typer.Option(2020, "--start-year", "-s", help="í¬ë¡¤ë§ ì‹œì‘ ì—°ë„"),
    headless: bool = typer.Option(config.HEADLESS, "--headless/--no-headless", help="í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ"),
    drive: bool = typer.Option(False, "--drive", help="êµ¬ê¸€ ë“œë¼ì´ë¸Œ ëª¨ë“œ (ì—…ë¡œë“œ ë° ë¡œì»¬ íŒŒì¼ ì‚­ì œ)"),
):
    """
    ì „ì²´ ê¸°ê°„ í¬ë¡¤ë§ (ì´ˆê¸° ìˆ˜ì§‘ìš©)
    
    ì§€ì •í•œ ì—°ë„ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ëª¨ë“  IPO ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    ê° ê¸°ì—… ìŠ¤í¬ë˜í•‘ ì§í›„ ì¦‰ì‹œ OHLC ë°ì´í„°ë¥¼ FDRë¡œ ì¡°íšŒí•˜ì—¬ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    deps = _build_dependencies(headless=headless)
    
    try:
        deps['logger'].info("=" * 60)
        deps['logger'].info("ğŸš€ Stock Crawler - ì „ì²´ í¬ë¡¤ë§")
        deps['logger'].info(f"ğŸ“… ê¸°ì¤€ ë‚ ì§œ: {date.today()}")
        deps['logger'].info(f"ğŸ“† í¬ë¡¤ë§ ì‹œì‘ ì—°ë„: {start_year}ë…„")
        deps['logger'].info(f"ğŸ’¾ ëª¨ë“œ: {'Google Drive' if drive else 'Local'}")
        deps['logger'].info("=" * 60)
        
        # Playwright ì´ˆê¸°í™”
        deps['page_provider'].setup()
        
        # í¬ë¡¤ë§ ì‹¤í–‰
        yearly_data = deps['crawler'].run(start_year=start_year)
        
        deps['logger'].info("=" * 60)
        deps['logger'].info("ğŸ ëª¨ë“  í¬ë¡¤ë§ ë° ë³´ê°• ì‘ì—… ì™„ë£Œ")
        
        # Google Drive ëª¨ë“œ ì²˜ë¦¬
        if drive:
            output_path = config.get_output_path(config.get_default_filename())
            try:
                if output_path.exists():
                    deps['logger'].info("â˜ï¸  Google Drive ì—…ë¡œë“œ ì‹œì‘...")
                    file_id = deps['storage'].upload_file(output_path)
                    deps['logger'].info(f"âœ… ì—…ë¡œë“œ ì„±ê³µ (ID: {file_id})")
            except Exception as e:
                deps['logger'].warning(f"âš ï¸  Google Drive ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            finally:
                # ë¡œì»¬ íŒŒì¼ ì‚­ì œ (Cleanup) - ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ì‚­ì œ
                if output_path.exists():
                    os.remove(output_path)
                    deps['logger'].info(f"ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {output_path}")
            
        deps['logger'].info("=" * 60)
        
    except KeyboardInterrupt:
        deps['logger'].warning("\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        deps['logger'].error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        deps['page_provider'].cleanup()
        deps['logger'].info("\nâœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")


@app.command("enrich")
def enrich_data(
    filepath: Optional[str] = typer.Option(
        None,
        "--file",
        "-f",
        help="ëŒ€ìƒ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ (ë¯¸ì§€ì • ì‹œ ìµœì‹  íŒŒì¼ ìë™ ê²€ìƒ‰)"
    ),
    drive: bool = typer.Option(False, "--drive", help="êµ¬ê¸€ ë“œë¼ì´ë¸Œ ëª¨ë“œ (ë‹¤ìš´ë¡œë“œ -> ë³´ê°• -> ì—…ë¡œë“œ -> ì‚­ì œ)"),
):
    """
    ê¸°ì¡´ ë°ì´í„°ì— OHLC ë³´ê°•
    
    ì´ë¯¸ ìˆ˜ì§‘ëœ ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì„œ OHLC ë°ì´í„°ì™€ ìˆ˜ìµë¥ ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    from core.services.enrichment_service import EnrichmentService
    from infra.adapters.data.fdr_adapter import FDRAdapter
    from infra.adapters.data.excel_exporter import ExcelExporter
    from infra.adapters.utils.console_logger import ConsoleLogger
    from infra.adapters.storage.google_drive_adapter import GoogleDriveAdapter
    from core.services.stock_price_enricher import StockPriceEnricher
    
    logger = ConsoleLogger()
    storage_adapter = GoogleDriveAdapter()
    
    logger.info("=" * 60)
    logger.info("ğŸ“ˆ ì‹œì„¸ ë³´ê°• ì‘ì—… ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")
    logger.info(f"ğŸ’¾ ëª¨ë“œ: {'Google Drive' if drive else 'Local'}")
    logger.info("=" * 60)
    
    target_path = None
    
    # 1. ëŒ€ìƒ íŒŒì¼ ê²°ì • (Drive vs Local)
    if drive:
        # Drive ëª¨ë“œ: ìµœì‹  íŒŒì¼ ê²€ìƒ‰ ë° ë‹¤ìš´ë¡œë“œ
        try:
            target_filename = config.get_default_filename()
            logger.info(f"ğŸ” Google Driveì—ì„œ íŒŒì¼ ê²€ìƒ‰ ì¤‘: {target_filename}")
            
            files = storage_adapter.list_files(f"name = '{target_filename}'")
            if not files:
                logger.error(f"âŒ Google Driveì— ëŒ€ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {target_filename}")
                raise typer.Exit(code=1)
                
            latest_file = files[0] # createdTime desc ì •ë ¬ë¨
            logger.info(f"    - ë°œê²¬: {latest_file['name']} (ID: {latest_file['id']})")
            
            # ë‹¤ìš´ë¡œë“œ (íŒŒì¼ëª… ìœ ì§€)
            target_path = config.get_output_path(latest_file['name'])
            logger.info(f"â¬‡ï¸  ë‹¤ìš´ë¡œë“œ ì¤‘: {target_path}")
            storage_adapter.download_file(latest_file['id'], target_path)
            
        except Exception as e:
            logger.error(f"âŒ Google Drive ì‘ì—… ì‹¤íŒ¨: {e}")
            raise typer.Exit(code=1)
    else:
        # Local ëª¨ë“œ
        if filepath:
            target_path = Path(filepath)
        else:
            target_path = config.get_latest_output_file()
            
        if not target_path or not target_path.exists():
            logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target_path}")
            logger.info("ğŸ’¡ íŒ: ë¨¼ì € í¬ë¡¤ëŸ¬ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš” (uv run crawler full)")
            raise typer.Exit(code=1)

    logger.info(f"ëŒ€ìƒ íŒŒì¼: {target_path}")
    
    # 2. ë°ì´í„° ë¡œë“œ ë° ë³´ê°•
    try:
        excel_file = pd.ExcelFile(target_path)
        yearly_data = {}
        
        for sheet_name in excel_file.sheet_names:
            try:
                year = int(sheet_name)
                df = pd.read_excel(target_path, sheet_name=sheet_name)
                yearly_data[year] = df
                logger.info(f"    - [{year}ë…„] {len(df)}ê±´ ë¡œë“œ ì™„ë£Œ")
            except ValueError:
                continue
        
        if not yearly_data:
            logger.warning("âŒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            raise typer.Exit(code=1)
        
        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        fdr_adapter = FDRAdapter()
        data_exporter = ExcelExporter()
        
        stock_enricher = StockPriceEnricher(
            ticker_mapper=fdr_adapter,
            market_data_provider=fdr_adapter,
            logger=logger
        )
        
        enrichment_service = EnrichmentService(
            stock_enricher=stock_enricher,
            data_exporter=data_exporter,
            logger=logger
        )
        
        # ë³´ê°• ì‹¤í–‰ (ì €ì¥ê¹Œì§€ ìˆ˜í–‰ë¨)
        enrichment_service.enrich_data(yearly_data)
        
        logger.info("=" * 60)
        logger.info("ğŸ ë³´ê°• ì‘ì—… ì™„ë£Œ")
        
        # 3. Drive ëª¨ë“œ í›„ì²˜ë¦¬ (ì—…ë¡œë“œ ë° ì‚­ì œ)
        if drive:
            output_path = config.get_output_path(config.get_default_filename())
            try:
                if output_path.exists():
                    logger.info("â˜ï¸  Google Drive ì—…ë¡œë“œ ì‹œì‘...")
                    file_id = storage_adapter.upload_file(output_path)
                    logger.info(f"âœ… ì—…ë¡œë“œ ì„±ê³µ (ID: {file_id})")
            except Exception as e:
                logger.warning(f"âš ï¸  Google Drive ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            finally:
                # ë¡œì»¬ íŒŒì¼ ì‚­ì œ (Cleanup)
                # ë‹¤ìš´ë¡œë“œ ë°›ì€ ì›ë³¸ íŒŒì¼ ì‚­ì œ
                if target_path and target_path.exists() and target_path != output_path:
                        os.remove(target_path)
                        
                # ìƒˆë¡œ ìƒì„±ëœ íŒŒì¼ ì‚­ì œ
                if output_path.exists():
                    os.remove(output_path)
                    logger.info(f"ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
            
        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"âŒ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


@app.command("daily")
def daily_update(
    target_date: Optional[str] = typer.Option(
        None,
        "--date",
        "-d",
        help="ëŒ€ìƒ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹), ê¸°ë³¸ê°’: ì˜¤ëŠ˜"
    ),
    headless: bool = typer.Option(config.HEADLESS, "--headless/--no-headless", help="í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ"),
    drive: bool = typer.Option(False, "--drive", help="êµ¬ê¸€ ë“œë¼ì´ë¸Œ ëª¨ë“œ (ì—…ë¡œë“œ ë° ë¡œì»¬ íŒŒì¼ ì‚­ì œ)"),
):
    """
    ì¼ì¼ ì—…ë°ì´íŠ¸ (GitHub Actionsìš©)
    
    íŠ¹ì • ë‚ ì§œì˜ IPO ë°ì´í„°ë§Œ í¬ë¡¤ë§í•˜ì—¬ ê¸°ì¡´ ì—‘ì…€ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    ë‚ ì§œë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
    """
    # ë‚ ì§œ íŒŒì‹±
    if target_date:
        try:
            parsed_date = datetime.strptime(target_date, "%Y-%m-%d").date()
        except ValueError:
            typer.echo("âŒ ë‚ ì§œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            raise typer.Exit(code=1)
    else:
        parsed_date = date.today()
    
    deps = _build_dependencies(headless=headless)
    
    try:
        deps['logger'].info("=" * 60)
        deps['logger'].info("ğŸ“… Stock Crawler - ì¼ì¼ ì—…ë°ì´íŠ¸")
        deps['logger'].info(f"ëŒ€ìƒ ë‚ ì§œ: {parsed_date}")
        deps['logger'].info(f"ğŸ’¾ ëª¨ë“œ: {'Google Drive' if drive else 'Local'}")
        deps['logger'].info("=" * 60)
        
        # Playwright ì´ˆê¸°í™”
        deps['page_provider'].setup()
        
        # ì¼ì¼ í¬ë¡¤ë§ ì‹¤í–‰
        new_data = deps['crawler'].run_daily(target_date=parsed_date)
        
        if new_data:
            total_count = sum(len(df) for df in new_data.values())
            deps['logger'].info(f"âœ… {total_count}ê±´ ì¶”ê°€ë¨")
        else:
            deps['logger'].info("â„¹ï¸  ì˜¤ëŠ˜ì€ ìƒì¥ ì˜ˆì • ì—†ìŒ")
        
        deps['logger'].info("=" * 60)
        deps['logger'].info("ğŸ ì¼ì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # Google Drive ëª¨ë“œ ì²˜ë¦¬
        if drive and new_data:
            output_path = config.get_output_path(config.get_default_filename())
            try:
                if output_path.exists():
                    deps['logger'].info("â˜ï¸  Google Drive ì—…ë¡œë“œ ì‹œì‘...")
                    file_id = deps['storage'].upload_file(output_path)
                    deps['logger'].info(f"âœ… ì—…ë¡œë“œ ì„±ê³µ (ID: {file_id})")
            except Exception as e:
                deps['logger'].warning(f"âš ï¸  Google Drive ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            finally:
                # ë¡œì»¬ íŒŒì¼ ì‚­ì œ (Cleanup)
                if output_path.exists():
                    os.remove(output_path)
                    deps['logger'].info(f"ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
                
        deps['logger'].info("=" * 60)
        
    except KeyboardInterrupt:
        deps['logger'].warning("\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        deps['logger'].error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        deps['page_provider'].cleanup()
        deps['logger'].info("\nâœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")


if __name__ == "__main__":
    app()
